{"cells":[{"metadata":{"_uuid":"7a6f3399-ae59-40c9-b974-c0be884e0acc","_cell_guid":"6aacd915-9f7c-47aa-b826-ba74e270d016","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/keystroke-dynamics-benchmark-data-set/DSL-StrongPasswordData.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# **DataSet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/keystroke-dynamics-benchmark-data-set/DSL-StrongPasswordData.csv\")\ndata.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"  subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n0    s002             1    1    0.1491       0.3979       0.2488  0.1069   \n1    s002             1    2    0.1111       0.3451       0.2340  0.0694   \n2    s002             1    3    0.1328       0.2072       0.0744  0.0731   \n3    s002             1    4    0.1291       0.2515       0.1224  0.1059   \n4    s002             1    5    0.1249       0.2317       0.1068  0.0895   \n\n   DD.t.i  UD.t.i     H.i  ...     H.a  DD.a.n  UD.a.n     H.n  DD.n.l  \\\n0  0.1674  0.0605  0.1169  ...  0.1349  0.1484  0.0135  0.0932  0.3515   \n1  0.1283  0.0589  0.0908  ...  0.1412  0.2558  0.1146  0.1146  0.2642   \n2  0.1291  0.0560  0.0821  ...  0.1621  0.2332  0.0711  0.1172  0.2705   \n3  0.2495  0.1436  0.1040  ...  0.1457  0.1629  0.0172  0.0866  0.2341   \n4  0.1676  0.0781  0.0903  ...  0.1312  0.1582  0.0270  0.0884  0.2517   \n\n   UD.n.l     H.l  DD.l.Return  UD.l.Return  H.Return  \n0  0.2583  0.1338       0.3509       0.2171    0.0742  \n1  0.1496  0.0839       0.2756       0.1917    0.0747  \n2  0.1533  0.1085       0.2847       0.1762    0.0945  \n3  0.1475  0.0845       0.3232       0.2387    0.0813  \n4  0.1633  0.0903       0.2517       0.1614    0.0818  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>sessionIndex</th>\n      <th>rep</th>\n      <th>H.period</th>\n      <th>DD.period.t</th>\n      <th>UD.period.t</th>\n      <th>H.t</th>\n      <th>DD.t.i</th>\n      <th>UD.t.i</th>\n      <th>H.i</th>\n      <th>...</th>\n      <th>H.a</th>\n      <th>DD.a.n</th>\n      <th>UD.a.n</th>\n      <th>H.n</th>\n      <th>DD.n.l</th>\n      <th>UD.n.l</th>\n      <th>H.l</th>\n      <th>DD.l.Return</th>\n      <th>UD.l.Return</th>\n      <th>H.Return</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.1491</td>\n      <td>0.3979</td>\n      <td>0.2488</td>\n      <td>0.1069</td>\n      <td>0.1674</td>\n      <td>0.0605</td>\n      <td>0.1169</td>\n      <td>...</td>\n      <td>0.1349</td>\n      <td>0.1484</td>\n      <td>0.0135</td>\n      <td>0.0932</td>\n      <td>0.3515</td>\n      <td>0.2583</td>\n      <td>0.1338</td>\n      <td>0.3509</td>\n      <td>0.2171</td>\n      <td>0.0742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.1111</td>\n      <td>0.3451</td>\n      <td>0.2340</td>\n      <td>0.0694</td>\n      <td>0.1283</td>\n      <td>0.0589</td>\n      <td>0.0908</td>\n      <td>...</td>\n      <td>0.1412</td>\n      <td>0.2558</td>\n      <td>0.1146</td>\n      <td>0.1146</td>\n      <td>0.2642</td>\n      <td>0.1496</td>\n      <td>0.0839</td>\n      <td>0.2756</td>\n      <td>0.1917</td>\n      <td>0.0747</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.1328</td>\n      <td>0.2072</td>\n      <td>0.0744</td>\n      <td>0.0731</td>\n      <td>0.1291</td>\n      <td>0.0560</td>\n      <td>0.0821</td>\n      <td>...</td>\n      <td>0.1621</td>\n      <td>0.2332</td>\n      <td>0.0711</td>\n      <td>0.1172</td>\n      <td>0.2705</td>\n      <td>0.1533</td>\n      <td>0.1085</td>\n      <td>0.2847</td>\n      <td>0.1762</td>\n      <td>0.0945</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.1291</td>\n      <td>0.2515</td>\n      <td>0.1224</td>\n      <td>0.1059</td>\n      <td>0.2495</td>\n      <td>0.1436</td>\n      <td>0.1040</td>\n      <td>...</td>\n      <td>0.1457</td>\n      <td>0.1629</td>\n      <td>0.0172</td>\n      <td>0.0866</td>\n      <td>0.2341</td>\n      <td>0.1475</td>\n      <td>0.0845</td>\n      <td>0.3232</td>\n      <td>0.2387</td>\n      <td>0.0813</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.1249</td>\n      <td>0.2317</td>\n      <td>0.1068</td>\n      <td>0.0895</td>\n      <td>0.1676</td>\n      <td>0.0781</td>\n      <td>0.0903</td>\n      <td>...</td>\n      <td>0.1312</td>\n      <td>0.1582</td>\n      <td>0.0270</td>\n      <td>0.0884</td>\n      <td>0.2517</td>\n      <td>0.1633</td>\n      <td>0.0903</td>\n      <td>0.2517</td>\n      <td>0.1614</td>\n      <td>0.0818</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(2,58):\n    colname = str((\"s00\" if i < 10 else \"s0\")+str(i))\n    #print(colname)\n    data[colname] = [1 if x ==colname else 0 for x in data['subject']]\ndata.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  subject  sessionIndex  rep  H.period  DD.period.t  UD.period.t     H.t  \\\n0    s002             1    1    0.1491       0.3979       0.2488  0.1069   \n1    s002             1    2    0.1111       0.3451       0.2340  0.0694   \n2    s002             1    3    0.1328       0.2072       0.0744  0.0731   \n3    s002             1    4    0.1291       0.2515       0.1224  0.1059   \n4    s002             1    5    0.1249       0.2317       0.1068  0.0895   \n\n   DD.t.i  UD.t.i     H.i  ...  s048  s049  s050  s051  s052  s053  s054  \\\n0  0.1674  0.0605  0.1169  ...     0     0     0     0     0     0     0   \n1  0.1283  0.0589  0.0908  ...     0     0     0     0     0     0     0   \n2  0.1291  0.0560  0.0821  ...     0     0     0     0     0     0     0   \n3  0.2495  0.1436  0.1040  ...     0     0     0     0     0     0     0   \n4  0.1676  0.0781  0.0903  ...     0     0     0     0     0     0     0   \n\n   s055  s056  s057  \n0     0     0     0  \n1     0     0     0  \n2     0     0     0  \n3     0     0     0  \n4     0     0     0  \n\n[5 rows x 90 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>sessionIndex</th>\n      <th>rep</th>\n      <th>H.period</th>\n      <th>DD.period.t</th>\n      <th>UD.period.t</th>\n      <th>H.t</th>\n      <th>DD.t.i</th>\n      <th>UD.t.i</th>\n      <th>H.i</th>\n      <th>...</th>\n      <th>s048</th>\n      <th>s049</th>\n      <th>s050</th>\n      <th>s051</th>\n      <th>s052</th>\n      <th>s053</th>\n      <th>s054</th>\n      <th>s055</th>\n      <th>s056</th>\n      <th>s057</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.1491</td>\n      <td>0.3979</td>\n      <td>0.2488</td>\n      <td>0.1069</td>\n      <td>0.1674</td>\n      <td>0.0605</td>\n      <td>0.1169</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.1111</td>\n      <td>0.3451</td>\n      <td>0.2340</td>\n      <td>0.0694</td>\n      <td>0.1283</td>\n      <td>0.0589</td>\n      <td>0.0908</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.1328</td>\n      <td>0.2072</td>\n      <td>0.0744</td>\n      <td>0.0731</td>\n      <td>0.1291</td>\n      <td>0.0560</td>\n      <td>0.0821</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.1291</td>\n      <td>0.2515</td>\n      <td>0.1224</td>\n      <td>0.1059</td>\n      <td>0.2495</td>\n      <td>0.1436</td>\n      <td>0.1040</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>s002</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.1249</td>\n      <td>0.2317</td>\n      <td>0.1068</td>\n      <td>0.0895</td>\n      <td>0.1676</td>\n      <td>0.0781</td>\n      <td>0.0903</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 90 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#take data of single subject\nsub = 's002'\npos_s2data = data[data['subject']==sub]\npos_s2data = pos_s2data.assign(output=pos_s2data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\n\n#take data of non-'s002' subjects\nneg_s2data = data[data['subject']!=sub]\nneg_s2data = neg_s2data.assign(output=neg_s2data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\nneg_s2data = neg_s2data.sample(400)\n\n#concating positive and negative samples to create our final data subset\ns2data = pd.concat([pos_s2data, neg_s2data],ignore_index=True)\ns2data = s2data.sample(frac=1) #shuffle the data\ns2data.head()\n\"\"\"\n","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"\"\\n#take data of single subject\\nsub = 's002'\\npos_s2data = data[data['subject']==sub]\\npos_s2data = pos_s2data.assign(output=pos_s2data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\\n\\n#take data of non-'s002' subjects\\nneg_s2data = data[data['subject']!=sub]\\nneg_s2data = neg_s2data.assign(output=neg_s2data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\\nneg_s2data = neg_s2data.sample(400)\\n\\n#concating positive and negative samples to create our final data subset\\ns2data = pd.concat([pos_s2data, neg_s2data],ignore_index=True)\\ns2data = s2data.sample(frac=1) #shuffle the data\\ns2data.head()\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"Index(['subject', 'sessionIndex', 'rep', 'H.period', 'DD.period.t',\n       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return', 's002',\n       's003', 's004', 's005', 's006', 's007', 's008', 's009', 's010', 's011',\n       's012', 's013', 's014', 's015', 's016', 's017', 's018', 's019', 's020',\n       's021', 's022', 's023', 's024', 's025', 's026', 's027', 's028', 's029',\n       's030', 's031', 's032', 's033', 's034', 's035', 's036', 's037', 's038',\n       's039', 's040', 's041', 's042', 's043', 's044', 's045', 's046', 's047',\n       's048', 's049', 's050', 's051', 's052', 's053', 's054', 's055', 's056',\n       's057'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputcols = ['s002', 's003', 's004', 's005', 's006', 's007', 's008', 's009', 's010',\n       's011', 's012', 's013', 's014', 's015', 's016', 's017', 's018', 's019','s020', 's021',\n       's022', 's023', 's024', 's025', 's026', 's027', 's028', 's029', 's030', 's031', 's032',\n       's033', 's034', 's035', 's036', 's037','s038', 's039', 's040', 's041', 's042', 's043',\n       's044', 's045', 's046', 's047', 's048', 's049', 's050', 's051', 's052', 's053', 's054', 's055','s056', 's057']","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data[['DD.period.t',\n       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return']]#.to_numpy().reshape(800,10,3)\n#print(x_s2[0])\ny = data[outputcols]#.to_numpy()\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2)\n#x_s2 = np.asarray(x_s2).astype('float32')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_s2train = x_s2[0:600]\n#x_s2test = x_s2[600:]\n#y_s2train = y_s2[0:600]\n#y_s2test = y_s2[600:]\nX_train = X_train.to_numpy().reshape(X_train.shape[0],10,3)\nX_test = X_test.to_numpy().reshape(X_test.shape[0],10,3)\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, GaussianDropout, Bidirectional\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\n\ninitializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(272, input_shape=(10,3), return_sequences='true', kernel_initializer=initializer, activation='tanh'))\nmodel.add(GaussianDropout(0.5))\nmodel.add(LSTM(272, return_sequences='true', activation='tanh'))\nmodel.add(GaussianDropout(0.5))\nmodel.add(LSTM(272, activation='tanh'))\nmodel.add(GaussianDropout(0.5))\nmodel.add(Dense(272, activation='tanh'))\nmodel.add(GaussianDropout(0.5))\nmodel.add(Dense(y_train.shape[1], activation='sigmoid'))\nmodel.compile(loss = 'BinaryCrossentropy', optimizer='adam',metrics = ['accuracy'])\n#print(model.summary())\n\nbatch_size = 32\nmodel.fit(X_train, y_train, epochs = 50, batch_size=batch_size, validation_split = 0.1, verbose = 1)\n\nscore,acc = model.evaluate(X_test, y_test, verbose = 1, batch_size = batch_size)\nprint(\"score: \"+str(score)+\" accuracy: \"+str(acc))","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n459/459 [==============================] - 4s 8ms/step - loss: 0.1044 - accuracy: 0.0185 - val_loss: 0.0888 - val_accuracy: 0.0214\nEpoch 2/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.0297 - val_loss: 0.0803 - val_accuracy: 0.0472\nEpoch 3/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0818 - accuracy: 0.0690 - val_loss: 0.0752 - val_accuracy: 0.1189\nEpoch 4/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0748 - accuracy: 0.1364 - val_loss: 0.0620 - val_accuracy: 0.3076\nEpoch 5/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0618 - accuracy: 0.2944 - val_loss: 0.0494 - val_accuracy: 0.4540\nEpoch 6/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0512 - accuracy: 0.4532 - val_loss: 0.0376 - val_accuracy: 0.6324\nEpoch 7/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0424 - accuracy: 0.5876 - val_loss: 0.0312 - val_accuracy: 0.6887\nEpoch 8/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0370 - accuracy: 0.6539 - val_loss: 0.0280 - val_accuracy: 0.7255\nEpoch 9/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0322 - accuracy: 0.7128 - val_loss: 0.0240 - val_accuracy: 0.7586\nEpoch 10/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0285 - accuracy: 0.7531 - val_loss: 0.0204 - val_accuracy: 0.8009\nEpoch 11/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.7751 - val_loss: 0.0189 - val_accuracy: 0.8156\nEpoch 12/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0240 - accuracy: 0.7951 - val_loss: 0.0182 - val_accuracy: 0.8137\nEpoch 13/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0221 - accuracy: 0.8135 - val_loss: 0.0167 - val_accuracy: 0.8327\nEpoch 14/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0204 - accuracy: 0.8286 - val_loss: 0.0149 - val_accuracy: 0.8536\nEpoch 15/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0190 - accuracy: 0.8426 - val_loss: 0.0149 - val_accuracy: 0.8609\nEpoch 16/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0178 - accuracy: 0.8574 - val_loss: 0.0157 - val_accuracy: 0.8425\nEpoch 17/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0172 - accuracy: 0.8595 - val_loss: 0.0152 - val_accuracy: 0.8480\nEpoch 18/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0162 - accuracy: 0.8682 - val_loss: 0.0143 - val_accuracy: 0.8701\nEpoch 19/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0156 - accuracy: 0.8757 - val_loss: 0.0150 - val_accuracy: 0.8560\nEpoch 20/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0150 - accuracy: 0.8811 - val_loss: 0.0136 - val_accuracy: 0.8732\nEpoch 21/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0141 - accuracy: 0.8872 - val_loss: 0.0139 - val_accuracy: 0.8676\nEpoch 22/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0138 - accuracy: 0.8908 - val_loss: 0.0121 - val_accuracy: 0.8909\nEpoch 23/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0126 - accuracy: 0.8986 - val_loss: 0.0122 - val_accuracy: 0.8909\nEpoch 24/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9018 - val_loss: 0.0148 - val_accuracy: 0.8738\nEpoch 25/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0116 - accuracy: 0.9107 - val_loss: 0.0130 - val_accuracy: 0.8854\nEpoch 26/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0115 - accuracy: 0.9112 - val_loss: 0.0127 - val_accuracy: 0.8909\nEpoch 27/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9143 - val_loss: 0.0121 - val_accuracy: 0.8958\nEpoch 28/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0105 - accuracy: 0.9180 - val_loss: 0.0127 - val_accuracy: 0.8903\nEpoch 29/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0096 - accuracy: 0.9264 - val_loss: 0.0129 - val_accuracy: 0.8915\nEpoch 30/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9248 - val_loss: 0.0121 - val_accuracy: 0.9038\nEpoch 31/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0090 - accuracy: 0.9330 - val_loss: 0.0135 - val_accuracy: 0.8940\nEpoch 32/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0088 - accuracy: 0.9344 - val_loss: 0.0136 - val_accuracy: 0.8891\nEpoch 33/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0089 - accuracy: 0.9336 - val_loss: 0.0123 - val_accuracy: 0.8995\nEpoch 34/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0082 - accuracy: 0.9408 - val_loss: 0.0134 - val_accuracy: 0.8934\nEpoch 35/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0085 - accuracy: 0.9400 - val_loss: 0.0128 - val_accuracy: 0.8977\nEpoch 36/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0078 - accuracy: 0.9439 - val_loss: 0.0115 - val_accuracy: 0.9099\nEpoch 37/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0077 - accuracy: 0.9441 - val_loss: 0.0119 - val_accuracy: 0.9032\nEpoch 38/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9472 - val_loss: 0.0152 - val_accuracy: 0.8842\nEpoch 39/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0069 - accuracy: 0.9502 - val_loss: 0.0129 - val_accuracy: 0.9050\nEpoch 40/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9499 - val_loss: 0.0145 - val_accuracy: 0.8952\nEpoch 41/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0063 - accuracy: 0.9574 - val_loss: 0.0134 - val_accuracy: 0.9026\nEpoch 42/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0071 - accuracy: 0.9482 - val_loss: 0.0141 - val_accuracy: 0.8989\nEpoch 43/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0065 - accuracy: 0.9548 - val_loss: 0.0135 - val_accuracy: 0.9038\nEpoch 44/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9566 - val_loss: 0.0146 - val_accuracy: 0.8971\nEpoch 45/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0060 - accuracy: 0.9598 - val_loss: 0.0131 - val_accuracy: 0.9044\nEpoch 46/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9579 - val_loss: 0.0158 - val_accuracy: 0.8989\nEpoch 47/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0057 - accuracy: 0.9612 - val_loss: 0.0134 - val_accuracy: 0.9075\nEpoch 48/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0052 - accuracy: 0.9649 - val_loss: 0.0137 - val_accuracy: 0.9081\nEpoch 49/50\n459/459 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9634 - val_loss: 0.0141 - val_accuracy: 0.9056\nEpoch 50/50\n459/459 [==============================] - 3s 7ms/step - loss: 0.0055 - accuracy: 0.9621 - val_loss: 0.0145 - val_accuracy: 0.9099\n128/128 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9140\nscore: 0.012883998453617096 accuracy: 0.9139705896377563\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub='s021'\nsubdata = data[data['subject']==sub] #data.assign(output=data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\nXsub = subdata[['DD.period.t',\n       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return']].to_numpy().reshape(subdata.shape[0],10,3)\nysub = subdata[outputcols].to_numpy()\n#xtotal = np.asarray(xtotal).astype('float32')\n\nscore,acc = model.evaluate(Xsub, ysub, verbose = 1, batch_size = batch_size)\nprint(\"score: \"+str(score)+\" accuracy: \"+str(acc))","execution_count":50,"outputs":[{"output_type":"stream","text":"13/13 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 0.9800\nscore: 0.003062942298129201 accuracy: 0.9800000190734863\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub='s002'\nsubdata = data[data['subject']!=sub] #data.assign(output=data.apply(lambda i: 1 if i['subject']==sub else 0 , axis = 1))\nXsub = subdata[['DD.period.t',\n       'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e',\n       'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r',\n       'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o',\n       'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l',\n       'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return']].to_numpy().reshape(subdata.shape[0],10,3)\nysub = subdata[outputcols].to_numpy()\n#xtotal = np.asarray(xtotal).astype('float32')\n\npredictions = model.predict(Xsub)\npred_df = pd.DataFrame(data = predictions, columns = outputcols)\npred_df[\"result\"] = [1 if x>0.5 else 0 for x in pred_df[sub]]\nsum(pred_df[\"result\"])\n#pred_df[\"result\"]","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"9"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}